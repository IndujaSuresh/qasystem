{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:47:44.785579Z","iopub.status.busy":"2024-09-06T07:47:44.785260Z","iopub.status.idle":"2024-09-06T07:52:06.792060Z","shell.execute_reply":"2024-09-06T07:52:06.791035Z","shell.execute_reply.started":"2024-09-06T07:47:44.785552Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-09-06 07:47:48.836187: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-09-06 07:47:48.836249: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-09-06 07:47:48.837664: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","Some weights of BertModel were not initialized from the model checkpoint at KooAI/KooBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["\n","Processing: /kaggle/input/language/malayalam.pdf\n","Detected language: ml\n","Number of documents created: 34\n","QA chain created for malayalam.pdf\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["\n","Processing: /kaggle/input/language/english.pdf\n","Detected language: en\n","Number of documents created: 33\n","QA chain created for english.pdf\n","All PDFs processed. You can now ask questions about these documents.\n"]},{"name":"stdout","output_type":"stream","text":["\n","Enter your query or 'exit' to quit:  നെൽപ്പാടങ്ങളിൽ കുഴൽപ്പുഴുവിനെ എങ്ങിനെ നശിപ്പിക്കാം ?\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_1250/1256610519.py:198: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n","  result = qa_chain({\"query\": user_input})\n"]},{"name":"stdout","output_type":"stream","text":["Answer (ml): നെൽപ്പാടങ്ങളിലെ പുഴുക്കളുടെ ആക്രമണം നിയന്ത്രിക്കാൻ നിരവധി രീതികൾ ഉപയോഗിക്കുന്നുണ്ട്. ഒന്നാമതായി, കള വെള്ളം മൂന്ന് ദിവസം വരെ സൂക്ഷിക്കുന്നത് ഒഴിവാക്കേണ്ടത് അത്യാവശ്യമാണ്. കൂടാതെ, അര ഏക്കർ സ്ഥലത്തേക്ക് 25 കിലോഗ്രാം അറക്ക് പൊടി കലർത്തി ഭൂമിയിൽ പുരട്ടുന്നത് ഫലപ്രദമായ ചികിത്സയാണ്. ഈ പ്രക്രിയയ്ക്ക് ശേഷം കൈറ്റൈൻ അടിസ്ഥാനമാക്കിയുള്ള സൂഡോമോണാസ് (20 ഗ്രാം ഒരു ലിറ്റർ വെള്ളത്തിൽ), അസാദിറാക്റ്റിൻ (750 മില്ലിലിറ്റർ ഒരു ഹെക്ടോറിൽ) എന്നിവയുടെ പ്രയോഗവും പരിഗണിക്കണം. രോഗം ബാധിച്ച പ്രദേശങ്ങൾക്ക് ചുറ്റും ട്രൈക്കോഡെർമ ഹാർസിയാനം (5 CC per hectare) അല്ലെങ്കിൽ ഫിറോമൻ കെണികൾ സ്ഥാപിക്കേണ്ടതുണ്ട്. അവസാനമായി, ബ്ലാസ്റ്റ് രോഗത്തിന്റെ ലക്ഷണങ്ങൾ നിരീക്ഷിക്കുകയും ആവശ്യമെങ്കിൽ ക്വിൻറൽഫോസ് (25 EC per hectare) പോലുള്ള രാസ കീടനാശിനികൾ പ്രയോഗിക്കുകയും വേണം. </s>\n"]},{"name":"stdout","output_type":"stream","text":["\n","Enter your query or 'exit' to quit:  നെൽചെടികളിലെ ഇലപ്പേൻ ഭാദയെപ്പറ്റി വിവരിക്കുക?\n"]},{"name":"stdout","output_type":"stream","text":["Answer (ml): നെല്ല് ചെടികളെ ബാധിക്കുന്ന ഒരു കീടം മൂലമുണ്ടാകുന്ന രോഗമാണ് ലീഫ് ഫാൾഡ് ഡിസീസ് എന്നും അറിയപ്പെടുന്ന നെല്ല് ഇലപ്പേൻ ഭാദ. ചെറിയ പ്രാണികളായ ടാൻസാനിയയിലെ നെല്ല് വിളകളെ നശിപ്പിക്കുന്നതിന് കാരണമാകുന്നതിനാൽ ഈ രോഗം പ്രാധാന്യമർഹിക്കുന്നു. രോഗത്തിന്‍റെ ലക്ഷണങ്ങളിൽ ഇലകളിലെ പാടുകൾ ഉൾപ്പെടുന്നു, അവിടെ അവയ്ക്ക് വെള്ള നിറമുള്ളതോ മഞ്ഞ നിറമുള്ളതോ ആയ അടയാളങ്ങളുണ്ട്. കൂടാതെ, ഇലയുടെ അറ്റങ്ങളും അരികുകളും ചുളിവുകളുള്ളതായി കാണപ്പെടാം, ചിലപ്പോൾ ഇലകൾ കത്തിപ്പോകുകയും ഒടുവിൽ ചത്തുപോകുകയും ചെയ്യും. </s>\n"]},{"name":"stdout","output_type":"stream","text":["\n","Enter your query or 'exit' to quit:  നെല്ലിൽ ഇലപ്പേൻ ലക്ഷണങ്ങൾ എന്തൊക്കെ ?\n"]},{"name":"stdout","output_type":"stream","text":["Answer (ml): നെല്ലിൻറെ മുന്തിരിപ്പഴത്തിലെ ലീഫ് പേൻ എന്നറിയപ്പെടുന്ന ഒരു തരം പ്രാണി മൂലമുണ്ടാകുന്ന അണുബാധയാണ് നെല്ലിൻറെ മുന്തിരിപ്പഴത്തിലെ ലീഫ് പേൻ (യൂറോപ്യൻ ലീഫ് പേൻ). ഈ പ്രാണി ചെടികളുടെ ഇലകളെ ഭക്ഷിക്കുകയും അവയ്ക്ക് കേടുപാടുകൾ വരുത്തുകയും ചെയ്യുന്നു. ഇത് സാധാരണയായി നെല്ലിന്‍റെ വിളയെ ബാധിക്കുന്നുണ്ടെങ്കിലും മറ്റ് തരത്തിലുള്ള ധാന്യങ്ങളിലും ഇത് കാണപ്പെടുന്നു. </s>\n"]},{"name":"stdout","output_type":"stream","text":["\n","Enter your query or 'exit' to quit:  What are the symptoms of Ants and Termite Attacks in rice crops?\n"]},{"name":"stdout","output_type":"stream","text":["Answer (en): Symptoms of ant attacks include eating the seeds and affecting germination, while termite attacks result in missing plants and reduced stand density due to feeding on the roots. Damage is primarily observed in upland rice, where cream-colored, small insects resemble ants with darker heads may be spotted. To manage these issues, increase the seed rate to counteract the effects of ants, apply chlorpyrifos 20 EC as a drench around the affected area, and irrigate the field if possible. </s>\n"]},{"name":"stdout","output_type":"stream","text":["\n","Enter your query or 'exit' to quit:  quit\n"]},{"name":"stdout","output_type":"stream","text":["Exiting the program. Goodbye!\n"]}],"source":["import torch\n","from langchain import  PromptTemplate\n","from langchain.chains import RetrievalQA\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.vectorstores import Chroma\n","from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n","import os\n","import re\n","import pickle\n","import fitz  # PyMuPDF\n","from langchain.schema import Document\n","import langdetect\n","from langchain_huggingface import HuggingFacePipeline\n","from langchain_huggingface import HuggingFaceEmbeddings\n","# Function to clean the output\n","def clean_output(output: str) -> str:\n","    # Find the position of [/INST]\n","    start_index = output.find('[/INST]') + len('[/INST]')\n","    \n","    # Extract the answer portion after [/INST]\n","    cleaned_output = output[start_index:].strip()\n","    \n","    # Remove any leading or trailing whitespace\n","    return cleaned_output\n","\n","\n","# Function to get device\n","DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Function to split text into paragraphs\n","def split_text_into_paragraphs(text_content):\n","    paragraphs = text_content.split('#')  # Split paragraphs based on two newlines\n","    return [paragraph.strip() for paragraph in paragraphs if paragraph.strip()]\n","\n","# Function to sanitize filenames\n","def sanitize_filename(filename):\n","    return re.sub(r'[^a-zA-Z0-9_-]', '_', filename)\n","\n","# Function to extract text from a PDF file\n","def extract_text_from_pdf(pdf_path):\n","    text_content = ''\n","    with fitz.open(pdf_path) as pdf_document:\n","        for page_num in range(len(pdf_document)):\n","            page = pdf_document[page_num]\n","            text_content += page.get_text()\n","    return text_content\n","\n","# Function to detect language\n","def detect_language(text):\n","    try:\n","        return langdetect.detect(text)\n","    except:\n","        return \"en\"  # Default to English if detection fails\n","\n","# Function to generate the prompt\n","def generate_prompt(prompt: str, system_prompt: str) -> str:\n","    return f\"\"\"\n","[INST] <>\n","{system_prompt}\n","<>\n","\n","{prompt} [/INST]\n","\"\"\".strip()\n","\n","\n","# Function to create embeddings\n","def create_embeddings(language):\n","    if language == \"en\":\n","        return HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n","    elif language == \"ml\":\n","        return HuggingFaceEmbeddings(model_name=\"KooAI/KooBERT\")\n","    else:\n","        raise ValueError(\"Unsupported language\")\n","\n","# Function to create the database\n","def create_database(documents, embeddings):\n","    db = Chroma.from_documents(documents, embeddings)\n","    return db\n","\n","# Function to create the retriever\n","def create_retriever(db):\n","    search_kwargs = {\"k\": 3}\n","    retriever = db.as_retriever(search_kwargs=search_kwargs)\n","    return retriever\n","\n","# Function to create the QA chain\n","def create_qa_chain(llm, retriever, prompt):\n","    qa_chain = RetrievalQA.from_chain_type(\n","        llm=llm,\n","        chain_type=\"stuff\",\n","        retriever=retriever,\n","        return_source_documents=True,\n","        chain_type_kwargs={\"prompt\": prompt},\n","    )\n","    return qa_chain\n","\n","# Function to create the LLM pipeline\n","def create_llm_pipeline(model, tokenizer):\n","    text_pipeline = pipeline(\n","        \"text-generation\",\n","        model=model,\n","        tokenizer=tokenizer,\n","        max_new_tokens=1024,\n","        temperature=0.1,\n","        top_p=0.95,\n","        repetition_penalty=1.15,\n","        device=DEVICE\n","    )\n","    llm = HuggingFacePipeline(pipeline=text_pipeline, model_kwargs={\"temperature\": 0})\n","    return llm\n","\n","def process_pdf_file(filename, pdf_path, embeddings, llm, prompt):\n","    print(f'\\nProcessing: {pdf_path}')\n","    text_content = extract_text_from_pdf(pdf_path)\n","    \n","    language = detect_language(text_content)\n","    print(f\"Detected language: {language}\")\n","\n","    paragraphs = split_text_into_paragraphs(text_content)\n","    documents = [Document(page_content=paragraph, metadata={\"language\": language, \"source\": pdf_path}) for paragraph in paragraphs]\n","    \n","    print(f\"Number of documents created: {len(documents)}\")\n","\n","    try:\n","        db = create_database(documents, embeddings)\n","        retriever = create_retriever(db)\n","        qa_chain = create_qa_chain(llm, retriever, prompt)\n","        \n","        print(f\"QA chain created for {filename}\")\n","        return qa_chain, language\n","    except Exception as e:\n","        print(f\"Error processing file {filename}: {e}\")\n","        return None, language\n","\n","# System prompt\n","SYSTEM_PROMPT = \"You are a helpful assistant for answering questions based on provided context. Explain the answer in paragraph!!\"\n","\n","def main():\n","    folder_path = './language/'  # Path to the folder containing PDFs\n","    model_pickle_path = './model.pkl'\n","\n","    if os.path.exists(model_pickle_path):\n","        with open(model_pickle_path, 'rb') as f:\n","            model, tokenizer = pickle.load(f)\n","    else:\n","        MODEL_NAME = \"sarvamai/sarvam-2b-v0.5\"\n","        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n","        tokenizer.pad_token = tokenizer.eos_token\n","\n","        model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(DEVICE)\n","        with open(model_pickle_path, 'wb') as f:\n","            pickle.dump((model, tokenizer), f)\n","\n","    llm = create_llm_pipeline(model, tokenizer)\n","\n","    # Create the PromptTemplate\n","    template = generate_prompt(\n","        \"{context}\\nQuestion: {question}\",\n","        system_prompt=SYSTEM_PROMPT,\n","    )\n","    prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n","\n","    language_doc_map = {\n","        \"en\": \"english.pdf\",\n","        \"ml\": \"malayalam.pdf\",\n","    }\n","\n","    qa_chains = {}\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith('.pdf'):\n","            pdf_path = os.path.join(folder_path, filename)\n","            text_content = extract_text_from_pdf(pdf_path)\n","            language = detect_language(text_content)\n","            embeddings = create_embeddings(language)\n","            qa_chain, doc_language = process_pdf_file(filename, pdf_path, embeddings, llm, prompt)\n","            qa_chains[doc_language] = (qa_chain, filename)\n","\n","    print(f\"All PDFs processed. You can now ask questions about these documents.\")\n","\n","    while True:\n","        user_input = input(\"\\nEnter your query or 'exit' to quit: \").strip()\n","        if user_input in ['exit', 'quit']:\n","            print(\"Exiting the program. Goodbye!\")\n","            break\n","\n","        if not user_input:\n","            print(\"Please enter a query.\")\n","            continue\n","\n","        query_language = detect_language(user_input)\n","\n","        if query_language in qa_chains:\n","            qa_chain, associated_file = qa_chains[query_language]\n","            expected_doc = language_doc_map.get(query_language)\n","\n","            if associated_file == expected_doc:\n","                try:\n","                    result = qa_chain({\"query\": user_input})\n","                    cleaned_answer = clean_output(result['result'])\n","                    print(f\"Answer ({query_language}):\", cleaned_answer)\n","                except Exception as e:\n","                    print(f\"Error while processing query: {e}\")\n","            else:\n","                print(f\"Query language detected as {query_language}, but no matching document found for {expected_doc}.\")\n","        else:\n","            print(f\"No document available for the detected language: {query_language}\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5570343,"sourceId":9212137,"sourceType":"datasetVersion"},{"datasetId":5572440,"sourceId":9215396,"sourceType":"datasetVersion"},{"datasetId":5572579,"sourceId":9215612,"sourceType":"datasetVersion"},{"datasetId":5573681,"sourceId":9217083,"sourceType":"datasetVersion"},{"datasetId":5573930,"sourceId":9217435,"sourceType":"datasetVersion"},{"datasetId":5653623,"sourceId":9330983,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
